import json
import re
from typing import Dict, List, Any, Tuple, Optional

class SimilarityCalculator:
    def __init__(self):
        # Agrupamento de campos por se√ß√£o
        self.section_fields = {
            'market_overview': ['market_cap', 'price_change', 'traders', 'buy_volume', 'sell_volume', 
                               'buy_count', 'sell_count', 'buyers', 'sellers'],


            'wallet_insights': ['holders_totais', 'smart_wallets', 'fresh_wallets', 'renowned_wallets',
                               'creator_wallets', 'sniper_wallets', 'rat_traders', 'whale_wallets',
                               'top_wallets', 'following_wallets', 'bluechip_holders', 'bundler_wallets'],
            'risk_metrics': ['bluechip_holders_percentage', 'rat_trader_supply_percentage', 
                            'bundler_supply_percentage', 'entrapment_supply_percentage', 
                            'degen_calls', 'sinais_tecnicos'],
            'top_holders': ['top_holders_percentage', 'top1_holder_percentage', 'top5_holders_percentage', 
                           'top10_holders_percentage', 'holders_concentration_ratio', 'holders_distribution_score',
                           'top_holders_sol_total', 'top5_holders_sol_total', 'top1_holder_sol_amount',
                           'holders_sol_distribution_score', 'holders_sol_concentration_ratio'],
            'source_wallets': ['source_wallets_percentage', 'source_wallets_count', 'source_wallets_avg_hops']
        }
        
        # Padr√µes para identificar se√ß√µes na mensagem
        self.section_patterns = {
            'market_overview': r'üìä Market Overview',


            'wallet_insights': r'üìä Wallet Insights',
            'risk_metrics': r'üìà Risk Metrics',
            'top_holders': r'üìä.*?Top 10 Holders',
            'source_wallets': r'üîç Source Wallets'
        }
    
    def calculate_field_similarity(self, value1, value2) -> float:
        """Calcula similaridade entre dois valores (num√©ricos ou strings) (0-100%)"""
        if value1 is None and value2 is None:
            return 100.0
        
        if value1 is None or value2 is None:
            return 0.0
        
        # Para strings, compara igualdade exata
        if isinstance(value1, str) or isinstance(value2, str):
            if str(value1).lower() == str(value2).lower():
                return 100.0
            else:
                return 0.0
        
        # Para valores num√©ricos
        if value1 == 0 and value2 == 0:
            return 100.0
        
        if value1 == 0 or value2 == 0:
            return 0.0
        
        # Calcula similaridade baseada na proximidade dos valores
        max_val = max(abs(value1), abs(value2))
        min_val = min(abs(value1), abs(value2))
        
        similarity = (min_val / max_val) * 100
        return similarity
    
    def calculate_section_similarity(self, token1: Dict[str, Any], token2: Dict[str, Any], section_name: str) -> float:
        """Calcula similaridade m√©dia para uma se√ß√£o espec√≠fica"""
        if section_name not in self.section_fields:
            return 0.0
        
        fields = self.section_fields[section_name]
        similarities = []
        
        # Para Top Holders, usa algoritmo sofisticado com pesos
        if section_name == 'top_holders':
            return self._calculate_holders_similarity(token1, token2)
        
        # Para Source Wallets, usa algoritmo com pesos
        if section_name == 'source_wallets':
            return self._calculate_source_wallets_similarity(token1, token2)
        
        # Para outras se√ß√µes, usa algoritmo padr√£o
        for field in fields:
            value1 = token1.get(field)
            value2 = token2.get(field)
            
            # S√≥ inclui no c√°lculo se pelo menos um dos valores existir
            if value1 is not None or value2 is not None:
                field_sim = self.calculate_field_similarity(value1, value2)
                similarities.append(field_sim)
        
        # Retorna a m√©dia das similaridades da se√ß√£o
        if similarities:
            return sum(similarities) / len(similarities)
        else:
            return 0.0
    
    def _calculate_holders_similarity(self, token1: Dict[str, Any], token2: Dict[str, Any]) -> float:
        """Algoritmo sofisticado para calcular similaridade dos Top 10 Holders (com an√°lise de SOL)"""
        
        # Pesos para diferentes aspectos da an√°lise (expandido com m√©tricas de SOL)
        weights = {
            'total_pct_weight': 15,          # Porcentagem total dos top 10
            'concentration_pct_weight': 20,  # Concentra√ß√£o do top 1 (%)
            'oligopoly_pct_weight': 15,      # Top 5 holders (%)
            'distribution_pct_weight': 15,   # Score de distribui√ß√£o (%)
            'sol_total_weight': 10,          # Total de SOL dos holders
            'sol_concentration_weight': 15,  # Concentra√ß√£o de SOL do top 1
            'sol_distribution_weight': 10    # Distribui√ß√£o de SOL
        }
        
        similarities = []
        
        # === M√âTRICAS DE PORCENTAGEM (65% do peso total) ===
        
        # 1. Similaridade do total (peso 15%)
        total1 = token1.get('top_holders_percentage')
        total2 = token2.get('top_holders_percentage')
        if total1 is not None and total2 is not None:
            total_sim = self.calculate_field_similarity(total1, total2)
            similarities.append(total_sim * weights['total_pct_weight'] / 100)
        
        # 2. Similaridade da concentra√ß√£o do top 1 holder (peso 20%)
        top1_1 = token1.get('top1_holder_percentage')
        top1_2 = token2.get('top1_holder_percentage')
        if top1_1 is not None and top1_2 is not None:
            concentration_sim = self.calculate_field_similarity(top1_1, top1_2)
            similarities.append(concentration_sim * weights['concentration_pct_weight'] / 100)
        
        # 3. Similaridade do oligop√≥lio (top 5) (peso 15%)
        top5_1 = token1.get('top5_holders_percentage')
        top5_2 = token2.get('top5_holders_percentage')
        if top5_1 is not None and top5_2 is not None:
            oligopoly_sim = self.calculate_field_similarity(top5_1, top5_2)
            similarities.append(oligopoly_sim * weights['oligopoly_pct_weight'] / 100)
        
        # 4. Similaridade da distribui√ß√£o (peso 15%)
        dist1 = token1.get('holders_distribution_score')
        dist2 = token2.get('holders_distribution_score')
        if dist1 is not None and dist2 is not None:
            distribution_sim = self.calculate_field_similarity(dist1, dist2)
            similarities.append(distribution_sim * weights['distribution_pct_weight'] / 100)
        
        # === M√âTRICAS DE SOL (35% do peso total) ===
        
        # 5. Similaridade do total de SOL (peso 10%)
        sol_total1 = token1.get('top_holders_sol_total')
        sol_total2 = token2.get('top_holders_sol_total')
        if sol_total1 is not None and sol_total2 is not None:
            sol_total_sim = self.calculate_field_similarity(sol_total1, sol_total2)
            similarities.append(sol_total_sim * weights['sol_total_weight'] / 100)
        
        # 6. Similaridade da concentra√ß√£o de SOL do top 1 (peso 15%)
        sol_conc1 = token1.get('holders_sol_concentration_ratio')
        sol_conc2 = token2.get('holders_sol_concentration_ratio')
        if sol_conc1 is not None and sol_conc2 is not None:
            sol_conc_sim = self.calculate_field_similarity(sol_conc1, sol_conc2)
            similarities.append(sol_conc_sim * weights['sol_concentration_weight'] / 100)
        
        # 7. Similaridade da distribui√ß√£o de SOL (peso 10%)
        sol_dist1 = token1.get('holders_sol_distribution_score')
        sol_dist2 = token2.get('holders_sol_distribution_score')
        if sol_dist1 is not None and sol_dist2 is not None:
            sol_dist_sim = self.calculate_field_similarity(sol_dist1, sol_dist2)
            similarities.append(sol_dist_sim * weights['sol_distribution_weight'] / 100)
        
        # Retorna a m√©dia ponderada
        if similarities:
            return sum(similarities)
        else:
            return 0.0
    
    def _calculate_source_wallets_similarity(self, token1: Dict[str, Any], token2: Dict[str, Any]) -> float:
        """Algoritmo para calcular similaridade dos Source Wallets"""
        
        # Pesos para diferentes aspectos da an√°lise
        weights = {
            'percentage_weight': 50,  # Porcentagem total (mais importante)
            'count_weight': 25,       # Quantidade de wallets
            'hops_weight': 25         # M√©dia de hops
        }
        
        similarities = []
        
        # 1. Similaridade da porcentagem total (peso 50%)
        pct1 = token1.get('source_wallets_percentage')
        pct2 = token2.get('source_wallets_percentage')
        if pct1 is not None and pct2 is not None:
            pct_sim = self.calculate_field_similarity(pct1, pct2)
            similarities.append(pct_sim * weights['percentage_weight'] / 100)
        
        # 2. Similaridade da quantidade de wallets (peso 25%)
        count1 = token1.get('source_wallets_count')
        count2 = token2.get('source_wallets_count')
        if count1 is not None and count2 is not None:
            count_sim = self.calculate_field_similarity(count1, count2)
            similarities.append(count_sim * weights['count_weight'] / 100)
        
        # 3. Similaridade da m√©dia de hops (peso 25%)
        hops1 = token1.get('source_wallets_avg_hops')
        hops2 = token2.get('source_wallets_avg_hops')
        if hops1 is not None and hops2 is not None:
            hops_sim = self.calculate_field_similarity(hops1, hops2)
            similarities.append(hops_sim * weights['hops_weight'] / 100)
        
        # Retorna a m√©dia ponderada
        if similarities:
            return sum(similarities)
        else:
            return 0.0
    
    def calculate_overall_similarity(self, token1: Dict[str, Any], token2: Dict[str, Any]) -> Tuple[float, Dict[str, float]]:
        """Calcula similaridade geral e por se√ß√£o"""
        section_similarities = {}
        total_similarity = 0.0
        valid_sections = 0
        
        for section_name in self.section_fields.keys():
            section_sim = self.calculate_section_similarity(token1, token2, section_name)
            # Inclui todas as se√ß√µes no dicion√°rio, mesmo com 0.0%
            section_similarities[section_name] = section_sim
            if section_sim > 0:  # S√≥ conta se√ß√µes > 0 para a m√©dia geral
                total_similarity += section_sim
                valid_sections += 1
        
        # Calcula similaridade geral como m√©dia das se√ß√µes
        overall_similarity = total_similarity / valid_sections if valid_sections > 0 else 0.0
        
        return overall_similarity, section_similarities
    
    def find_most_similar_token(self, target_token: Dict[str, Any], database_tokens: List[Dict[str, Any]]) -> Tuple[Optional[Dict[str, Any]], float, Dict[str, float]]:
        """Encontra o token mais similar no banco de dados"""
        if not database_tokens:
            return None, 0.0, {}
        
        best_match = None
        best_similarity = 0.0
        best_section_similarities = {}
        
        for db_token in database_tokens:
            similarity, section_sims = self.calculate_overall_similarity(target_token, db_token)
            
            if similarity > best_similarity:
                best_similarity = similarity
                best_match = db_token
                best_section_similarities = section_sims
        
        return best_match, best_similarity, best_section_similarities
    
    def _clean_emojis_from_message(self, message: str) -> str:
        """Remove emojis espec√≠ficos da mensagem"""
        # Remove os emojis üü£üëÄüü¢ 
        emojis_to_remove = ['üü£', 'üëÄüü¢', 'üëÄ', 'üü¢']
        cleaned_message = message
        
        for emoji in emojis_to_remove:
            cleaned_message = cleaned_message.replace(emoji, '')
        
        # Remove apenas espa√ßos extras no final das linhas, preservando quebras de linha
        lines = cleaned_message.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # Remove espa√ßos extras dentro da linha, mas preserva a estrutura
            cleaned_line = re.sub(r' +', ' ', line.strip())
            cleaned_lines.append(cleaned_line)
        
        return '\n'.join(cleaned_lines)
    
    def insert_similarities_in_message(self, original_message: str, section_similarities: Dict[str, float]) -> str:
        """Insere linhas de similaridade na mensagem original ap√≥s cada se√ß√£o"""
        if not original_message:
            return "‚ùå Mensagem original n√£o encontrada no banco de dados."
        
        # Limpa emojis indesejados da mensagem
        cleaned_message = self._clean_emojis_from_message(original_message)
        
        lines = cleaned_message.split('\n')
        result_lines = []
        
        i = 0
        while i < len(lines):
            line = lines[i]
            result_lines.append(line)
            
            # Verifica se esta linha marca o in√≠cio de uma se√ß√£o
            section_found = None
            similarity_pct = 0
            
            for section_name, pattern in self.section_patterns.items():
                if re.search(pattern, line):
                    section_found = section_name
                    similarity_pct = section_similarities.get(section_name, 30)  # Default 30% se n√£o calculado
                    break
            
            if section_found:
                # Encontra o final desta se√ß√£o
                section_end = i + 1
                while section_end < len(lines):
                    next_line = lines[section_end]
                    
                    # Para se encontrar linha vazia ou in√≠cio de nova se√ß√£o com emoji
                    if (next_line.strip() == '' or 
                        any(re.search(pattern, next_line) for pattern in self.section_patterns.values())):
                        break
                    
                    result_lines.append(next_line)
                    section_end += 1
                
                # Insere linha de similaridade ap√≥s a se√ß√£o
                result_lines.append(f"========================> üéØSimilaridade: {similarity_pct:.0f}%")
                
                # Adiciona linha vazia se a pr√≥xima linha n√£o for vazia
                if section_end < len(lines) and lines[section_end].strip() != '':
                    result_lines.append("")
                
                i = section_end
            else:
                i += 1
        
        return '\n'.join(result_lines)
    
    def extract_formatted_data(self, token_data: Dict[str, Any], raw_message: Optional[str] = None) -> Dict[str, str]:
        """Extrai dados formatados para compara√ß√£o lado a lado"""
        formatted_data = {}
        
        # Market Overview
        formatted_data['market_cap'] = self._format_currency(token_data.get('market_cap'))
        formatted_data['buy_volume'] = self._format_currency(token_data.get('buy_volume'))
        formatted_data['sell_volume'] = self._format_currency(token_data.get('sell_volume'))
        formatted_data['price_change'] = self._format_percentage(token_data.get('price_change'))
        formatted_data['traders'] = self._format_number(token_data.get('traders'))
        formatted_data['buy_count'] = self._format_number(token_data.get('buy_count'))
        formatted_data['sell_count'] = self._format_number(token_data.get('sell_count'))
        formatted_data['buyers'] = self._format_number(token_data.get('buyers'))
        formatted_data['sellers'] = self._format_number(token_data.get('sellers'))
        

        
        # Wallet Insights
        formatted_data['holders_totais'] = self._format_number(token_data.get('holders_totais'))
        formatted_data['smart_wallets'] = self._format_number(token_data.get('smart_wallets'))
        formatted_data['fresh_wallets'] = self._format_number(token_data.get('fresh_wallets'))
        formatted_data['renowned_wallets'] = self._format_number(token_data.get('renowned_wallets'))
        formatted_data['creator_wallets'] = self._format_number(token_data.get('creator_wallets'))
        formatted_data['sniper_wallets'] = self._format_number(token_data.get('sniper_wallets'))
        formatted_data['rat_traders'] = self._format_number(token_data.get('rat_traders'))
        formatted_data['whale_wallets'] = self._format_number(token_data.get('whale_wallets'))
        formatted_data['top_wallets'] = self._format_number(token_data.get('top_wallets'))
        formatted_data['following_wallets'] = self._format_number(token_data.get('following_wallets'))
        formatted_data['bluechip_holders'] = self._format_number(token_data.get('bluechip_holders'))
        formatted_data['bundler_wallets'] = self._format_number(token_data.get('bundler_wallets'))
        
        # Risk Metrics
        formatted_data['bluechip_holders_percentage'] = self._format_percentage(token_data.get('bluechip_holders_percentage'))
        formatted_data['rat_trader_supply_percentage'] = self._format_percentage(token_data.get('rat_trader_supply_percentage'))
        formatted_data['bundler_supply_percentage'] = self._format_percentage(token_data.get('bundler_supply_percentage'))
        formatted_data['degen_calls'] = self._format_number(token_data.get('degen_calls'))
        
        # Top Holders
        formatted_data['top_holders_percentage'] = self._format_percentage(token_data.get('top_holders_percentage'))
        formatted_data['top1_holder_percentage'] = self._format_percentage(token_data.get('top1_holder_percentage'))
        formatted_data['top5_holders_percentage'] = self._format_percentage(token_data.get('top5_holders_percentage'))
        
        # Source Wallets
        formatted_data['source_wallets_percentage'] = self._format_percentage(token_data.get('source_wallets_percentage'))
        formatted_data['source_wallets_count'] = self._format_number(token_data.get('source_wallets_count'))
        formatted_data['source_wallets_avg_hops'] = self._format_decimal(token_data.get('source_wallets_avg_hops'))
        
        return formatted_data
    
    def _format_currency(self, value) -> str:
        """Formata valores monet√°rios"""
        if value is None:
            return "N/A"
        if value >= 1_000_000:
            return f"${value/1_000_000:.2f}M"
        elif value >= 1_000:
            return f"${value/1_000:.2f}K"
        else:
            return f"${value:.2f}"
    
    def _format_percentage(self, value) -> str:
        """Formata porcentagens"""
        if value is None:
            return "N/A"
        if value >= 0:
            return f"+{value:.2f}%"
        else:
            return f"{value:.2f}%"
    
    def _format_number(self, value) -> str:
        """Formata n√∫meros inteiros"""
        if value is None:
            return "N/A"
        return f"{value:,}"
    
    def _format_decimal(self, value) -> str:
        """Formata n√∫meros decimais"""
        if value is None:
            return "N/A"
        return f"{value:.1f}"
    
    def create_side_by_side_comparison(self, current_token_data: Dict[str, Any], similar_token_data: Dict[str, Any], 
                                     section_similarities: Dict[str, float]) -> str:
        """Cria compara√ß√£o lado a lado com formata√ß√£o mono-espa√ßada (estilo terminal)"""
        
        # Extrai dados formatados
        current_formatted = self.extract_formatted_data(current_token_data)
        similar_formatted = self.extract_formatted_data(similar_token_data)
        
        # Nomes dos tokens para cabe√ßalho
        current_token_name = current_token_data.get('token_name', 'Token Atual')
        similar_token_name = similar_token_data.get('token_name', 'Token BD')
        
        comparison_lines = []
        
        # Filtra se√ß√µes com similaridade > 30% para evitar mensagens muito longas
        MIN_SECTION_SIMILARITY = 30.0
        
        # Market Overview
        if section_similarities.get('market_overview', 0) > MIN_SECTION_SIMILARITY:
            comparison_lines.append("Market Overview:")
            comparison_lines.append(f"‚îú Market Cap:         {current_formatted['market_cap']:>8} | {similar_formatted['market_cap']:>8}")
            comparison_lines.append(f"‚îú Buy Volume:         {current_formatted['buy_volume']:>8} | {similar_formatted['buy_volume']:>8}")
            comparison_lines.append(f"‚îú Sell Volume:        {current_formatted['sell_volume']:>8} | {similar_formatted['sell_volume']:>8}")
            comparison_lines.append(f"‚îú Price%:             {current_formatted['price_change']:>8} | {similar_formatted['price_change']:>8}")
            comparison_lines.append(f"‚îú Traders:            {current_formatted['traders']:>8} | {similar_formatted['traders']:>8}")
            comparison_lines.append(f"‚îú Buy Count:          {current_formatted['buy_count']:>8} | {similar_formatted['buy_count']:>8}")
            comparison_lines.append(f"‚îú Sell Count:         {current_formatted['sell_count']:>8} | {similar_formatted['sell_count']:>8}")
            comparison_lines.append(f"‚îú Buyers:             {current_formatted['buyers']:>8} | {similar_formatted['buyers']:>8}")
            comparison_lines.append(f"‚îî Sellers:            {current_formatted['sellers']:>8} | {similar_formatted['sellers']:>8}")
            comparison_lines.append(f"========================> üéØSimilaridade: {section_similarities.get('market_overview', 0):.0f}%")
            comparison_lines.append("")
        

        
        # Wallet Insights
        if section_similarities.get('wallet_insights', 0) > MIN_SECTION_SIMILARITY:
            comparison_lines.append("Wallet Insights:")
            comparison_lines.append(f"‚îú Holders Totais:     {current_formatted['holders_totais']:>8} | {similar_formatted['holders_totais']:>8}")
            comparison_lines.append(f"‚îú Smart Wallets:      {current_formatted['smart_wallets']:>8} | {similar_formatted['smart_wallets']:>8}")
            comparison_lines.append(f"‚îú Fresh Wallets:      {current_formatted['fresh_wallets']:>8} | {similar_formatted['fresh_wallets']:>8}")
            comparison_lines.append(f"‚îú Renowned Wallets:   {current_formatted['renowned_wallets']:>8} | {similar_formatted['renowned_wallets']:>8}")
            comparison_lines.append(f"‚îú Creator Wallets:    {current_formatted['creator_wallets']:>8} | {similar_formatted['creator_wallets']:>8}")
            comparison_lines.append(f"‚îú Sniper Wallets:     {current_formatted['sniper_wallets']:>8} | {similar_formatted['sniper_wallets']:>8}")
            comparison_lines.append(f"‚îú Rat Traders:        {current_formatted['rat_traders']:>8} | {similar_formatted['rat_traders']:>8}")
            comparison_lines.append(f"‚îú Whale Wallets:      {current_formatted['whale_wallets']:>8} | {similar_formatted['whale_wallets']:>8}")
            comparison_lines.append(f"‚îú Top Wallets:        {current_formatted['top_wallets']:>8} | {similar_formatted['top_wallets']:>8}")
            comparison_lines.append(f"‚îú Following Wallets:  {current_formatted['following_wallets']:>8} | {similar_formatted['following_wallets']:>8}")
            comparison_lines.append(f"‚îú Bluechip Holders:   {current_formatted['bluechip_holders']:>8} | {similar_formatted['bluechip_holders']:>8}")
            comparison_lines.append(f"‚îî Bundler Wallets:    {current_formatted['bundler_wallets']:>8} | {similar_formatted['bundler_wallets']:>8}")
            comparison_lines.append(f"========================> üéØSimilaridade: {section_similarities.get('wallet_insights', 0):.0f}%")
            comparison_lines.append("")
        
        # Risk Metrics
        if section_similarities.get('risk_metrics', 0) > MIN_SECTION_SIMILARITY:
            comparison_lines.append("Risk Metrics:")
            comparison_lines.append(f"‚îú Bluechip Holders:   {current_formatted['bluechip_holders_percentage']:>8} | {similar_formatted['bluechip_holders_percentage']:>8}")
            comparison_lines.append(f"‚îú Rat Trader Supply:  {current_formatted['rat_trader_supply_percentage']:>8} | {similar_formatted['rat_trader_supply_percentage']:>8}")
            comparison_lines.append(f"‚îî Bundler Supply:     {current_formatted['bundler_supply_percentage']:>8} | {similar_formatted['bundler_supply_percentage']:>8}")
            comparison_lines.append(f"========================> üéØSimilaridade: {section_similarities.get('risk_metrics', 0):.0f}%")
            comparison_lines.append("")
        
        # Top Holders
        if section_similarities.get('top_holders', 0) > MIN_SECTION_SIMILARITY:
            comparison_lines.append("Top 10 Holders:")
            comparison_lines.append(f"‚îú Top 10 Total:       {current_formatted['top_holders_percentage']:>8} | {similar_formatted['top_holders_percentage']:>8}")
            comparison_lines.append(f"‚îú Top 1 Holder:       {current_formatted['top1_holder_percentage']:>8} | {similar_formatted['top1_holder_percentage']:>8}")
            comparison_lines.append(f"‚îî Top 5 Holders:      {current_formatted['top5_holders_percentage']:>8} | {similar_formatted['top5_holders_percentage']:>8}")
            comparison_lines.append(f"========================> üéØSimilaridade: {section_similarities.get('top_holders', 0):.0f}%")
            comparison_lines.append("")
        
        # Source Wallets
        if section_similarities.get('source_wallets', 0) > MIN_SECTION_SIMILARITY:
            comparison_lines.append("Source Wallets:")
            comparison_lines.append(f"‚îú Percentage:         {current_formatted['source_wallets_percentage']:>8} | {similar_formatted['source_wallets_percentage']:>8}")
            comparison_lines.append(f"‚îú Count:              {current_formatted['source_wallets_count']:>8} | {similar_formatted['source_wallets_count']:>8}")
            comparison_lines.append(f"‚îî Avg Hops:           {current_formatted['source_wallets_avg_hops']:>8} | {similar_formatted['source_wallets_avg_hops']:>8}")
            comparison_lines.append(f"========================> üéØSimilaridade: {section_similarities.get('source_wallets', 0):.0f}%")
            comparison_lines.append("")
        
        # Se n√£o h√° se√ß√µes com similaridade > 30%, exibe resumo b√°sico
        if not comparison_lines:
            comparison_lines.append("RESUMO R√ÅPIDO:")
            comparison_lines.append(f"‚îú Similaridade Geral: {max(section_similarities.values(), default=0):.1f}%")
            comparison_lines.append(f"‚îî Nenhuma se√ß√£o com similaridade > {MIN_SECTION_SIMILARITY}%")
            comparison_lines.append("")
        
        return '\n'.join(comparison_lines)
    
    def create_enhanced_message(self, target_token_name: str, most_similar_token: Optional[Dict[str, Any]], 
                               similarity: float, section_similarities: Dict[str, float], 
                               current_message: Optional[str] = None, contract_address: Optional[str] = None) -> str:
        """Cria a mensagem final com formata√ß√£o mono-espa√ßada (estilo terminal)"""
        if not most_similar_token:
            ca_info = f"\nCA: `{contract_address}`" if contract_address else ""
            return f"Token: {target_token_name}{ca_info}\n\nNenhum token similar encontrado no banco de dados."
        
        # Usa a mensagem atual enviada pelo usu√°rio
        if not current_message:
            ca_info = f"\nCA: `{contract_address}`" if contract_address else ""
            return f"Token: {target_token_name}{ca_info}\n\nMensagem atual n√£o encontrada."
        
        # Nome do token mais similar
        similar_token_name = most_similar_token.get('token_name', 'Token desconhecido')
        
        # Criar relat√≥rio com formata√ß√£o mono-espa√ßada (estilo terminal)
        report_lines = []
        report_lines.append("```")
        report_lines.append("AN√ÅLISE DE SIMILARIDADE")
        report_lines.append("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        report_lines.append(f"Token Analisado:     {target_token_name}")
        
        # Adiciona CA do token analisado se dispon√≠vel
        if contract_address:
            report_lines.append(f"CA:  {contract_address}")
        else:
            report_lines.append(f"CA:                  N√£o dispon√≠vel")
        
        report_lines.append(f"Token Mais Similar:  {similar_token_name}")
        
        # Adiciona CA do token mais similar do banco de dados
        similar_contract_address = most_similar_token.get('contract_address')
        if similar_contract_address:
            report_lines.append(f"CA:  {similar_contract_address}")
        else:
            report_lines.append(f"CA:                  N√£o dispon√≠vel")
            
        report_lines.append(f"Similaridade Geral:  {similarity:.1f}%")
        report_lines.append("")
        
        # Se√ß√µes de similaridade com caracteres de √°rvore
        report_lines.append("Similaridades por se√ß√£o:")
        section_names = {
            'market_overview': 'Market Overview',
            'wallet_insights': 'Wallet Insights',
            'risk_metrics': 'Risk Metrics',
            'top_holders': 'Top 10 Holders',
            'source_wallets': 'Source Wallets'
        }
        
        section_keys = list(section_names.keys())
        # Calcula o tamanho m√°ximo dos nomes das se√ß√µes para alinhamento
        max_section_name_length = max(len(name) for name in section_names.values())
        
        for i, (section_key, section_name) in enumerate(section_names.items()):
            similarity_value = section_similarities.get(section_key, 0.0)
            tree_char = "‚îî" if i == len(section_keys) - 1 else "‚îú"
            # Alinha o nome da se√ß√£o √† esquerda com espa√ßamento fixo
            padded_name = f"{section_name}:".ljust(max_section_name_length + 1)
            report_lines.append(f"{tree_char} {padded_name}      {similarity_value:.1f}%")
        
        report_lines.append("")
        report_lines.append("Lado esquerdo ATUAL direito BANCO DE DADOS")
        report_lines.append("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        report_lines.append("```")
        
        return '\n'.join(report_lines)
    
    def get_social_links_section(self, current_message: str, message_entities: Optional[List] = None) -> str:
        """Copia a se√ß√£o completa de Social Links da mensagem original e aplica hiperlinks invis√≠veis"""
        if not current_message:
            return ""
        
        # Procura e copia a se√ß√£o completa de Social Links
        social_section_match = re.search(r'(üåê\s*Social Links:.*?)(?=\n\n|\n[üìäüìàüë•üîç]|$)', current_message, re.DOTALL)
        if not social_section_match:
            return ""
        
        social_links_text = social_section_match.group(1).strip()
        
        # Se h√° entidades de mensagem, aplica hiperlinks invis√≠veis
        if message_entities:
            social_links_with_entities = self._apply_invisible_hyperlinks(social_links_text, current_message, message_entities)
            if social_links_with_entities:
                social_links_text = social_links_with_entities
        
        # Converte URLs vis√≠veis em hiperlinks HTML clic√°veis
        return self._convert_urls_to_hyperlinks(social_links_text)
    
    def _apply_invisible_hyperlinks(self, social_text: str, full_message: str, entities: list) -> str:
        """Aplica hiperlinks invis√≠veis da mensagem aos textos dos social links - vers√£o robusta"""
        import logging
        logger = logging.getLogger(__name__)
        
        # Encontra todas as entidades text_link na mensagem
        text_link_entities = [e for e in entities if e.type == 'text_link' and hasattr(e, 'url')]
        
        if not text_link_entities:
            logger.info("üîç DEBUG: Nenhuma entidade text_link encontrada")
            return social_text
        
        logger.info(f"üîç DEBUG: {len(text_link_entities)} entidades text_link encontradas")
        
        result_text = social_text
        applied_links = 0
        
        # Para cada entidade text_link, tenta mapear para palavras na se√ß√£o Social Links
        for i, entity in enumerate(text_link_entities):
            try:
                # Extrai o texto da entidade da mensagem completa
                entity_text = full_message[entity.offset:entity.offset + entity.length]
                logger.info(f"üîó DEBUG: Entidade {i+1}: '{entity_text}' -> {entity.url}")
                
                # Tenta encontrar palavras-chave na se√ß√£o Social Links
                potential_matches = []
                
                # Lista de palavras-chave comuns nos social links - ordem de prioridade
                if 'twitter' in entity.url.lower() or 'x.com' in entity.url.lower():
                    potential_matches = ['Perfil', 'Profile', 'Twitter']  # Perfil primeiro para prioridade
                elif 'axiom' in entity.url.lower():
                    potential_matches = ['AXI', 'Axiom']
                elif 'telegram' in entity.url.lower():
                    potential_matches = ['Telegram', 'TG']
                else:
                    # Tenta usar o pr√≥prio texto da entidade e palavras gen√©ricas
                    potential_matches = [entity_text, 'Perfil', 'Profile']
                
                logger.info(f"üéØ DEBUG: Procurando matches para: {potential_matches}")
                
                # Procura matches na se√ß√£o Social Links
                for match_word in potential_matches:
                    # Procura a palavra exata no texto (case insensitive)
                    import re
                    pattern = r'\b' + re.escape(match_word) + r'\b'
                    match = re.search(pattern, result_text, re.IGNORECASE)
                    
                    if match:
                        logger.info(f"üéØ DEBUG: Match encontrado: '{match.group()}' na posi√ß√£o {match.start()}-{match.end()}")
                        
                        # Verifica se j√° n√£o foi processado
                        if f'<a href="{entity.url}">' not in result_text:
                            # Substitui a palavra pelo link HTML
                            result_text = result_text[:match.start()] + f'<a href="{entity.url}">{match.group()}</a>' + result_text[match.end():]
                            applied_links += 1
                            logger.info(f"‚úÖ DEBUG: Link aplicado - '{match.group()}' -> {entity.url}")
                            break
                        else:
                            logger.info(f"üîç DEBUG: Link '{match.group()}' j√° foi processado")
                            break
                    else:
                        logger.info(f"‚ùå DEBUG: Palavra '{match_word}' n√£o encontrada no texto")
                
                if not any(re.search(r'\b' + re.escape(match_word) + r'\b', result_text, re.IGNORECASE) for match_word in potential_matches):
                    logger.info(f"‚ö†Ô∏è DEBUG: Nenhum match encontrado para '{entity_text}' com URL {entity.url}")
                    # Log adicional para debug do texto social
                    logger.info(f"üîç DEBUG: Texto social atual: {result_text[:200]}...")
                    
            except Exception as e:
                logger.error(f"‚ùå DEBUG: Erro processando entidade {i+1}: {e}")
        
        logger.info(f"üéØ DEBUG: Total de links aplicados: {applied_links}")
        logger.info(f"üìù DEBUG: Texto final: {result_text[:200]}...")
        return result_text
    
    def _convert_urls_to_hyperlinks(self, text: str) -> str:
        """Converte URLs em texto para hiperlinks HTML clic√°veis - detecta m√∫ltiplos formatos"""
        import logging
        logger = logging.getLogger(__name__)
        
        result = text
        logger.info(f"üîó DEBUG: Processando URLs no texto: {result[:200]}...")
        
        # 1. Detectar e converter links markdown [texto](url)
        markdown_pattern = r'\[([^\]]+)\]\((https?://[^\)]+)\)'
        def replace_markdown(match):
            texto = match.group(1)
            url = match.group(2)
            logger.info(f"üìù DEBUG: Link markdown encontrado: [{texto}]({url})")
            return f'<a href="{url}">{texto}</a>'
        result = re.sub(markdown_pattern, replace_markdown, result)
        
        # 2. Detectar e converter URLs em par√™nteses (url) - apenas se n√£o foram processadas como markdown
        parentheses_pattern = r'\((https?://[^\)]+)\)'
        def replace_parentheses(match):
            url = match.group(1)
            logger.info(f"üìù DEBUG: URL em par√™nteses encontrada: ({url})")
            return f'(<a href="{url}">{url}</a>)'
        # S√≥ aplicar se n√£o h√° links markdown processados
        if '[' not in text or '](' not in text:
            result = re.sub(parentheses_pattern, replace_parentheses, result)
        
        # 3. NOVO: Detectar padr√£o espec√≠fico "Perfil - XXX KeyFollowers" e tentar aplicar link baseado em contexto
        perfil_pattern = r'(Perfil)\s*-\s*(\d+\s*KeyFollowers)'
        perfil_matches = list(re.finditer(perfil_pattern, result, re.IGNORECASE))
        if perfil_matches and '<a href=' not in result:
            logger.info(f"üéØ DEBUG: Encontrado padr√£o Perfil sem link - tentando detectar URL pr√≥xima")
            
            # Procura por URLs pr√≥ximas no texto original que possam ser do perfil
            twitter_url_pattern = r'(https?://(?:twitter\.com|x\.com)/[^\s\)]+)'
            twitter_urls = re.findall(twitter_url_pattern, text, re.IGNORECASE)
            
            if twitter_urls:
                # Aplica o primeiro URL do Twitter/X encontrado ao Perfil
                twitter_url = twitter_urls[0]
                logger.info(f"üîó DEBUG: Aplicando URL {twitter_url} ao Perfil")
                result = re.sub(perfil_pattern, f'<a href="{twitter_url}">\\1</a> - \\2', result, flags=re.IGNORECASE)
        
        # 4. Preservar links HTML existentes (n√£o modificar)
        # Links HTML j√° est√£o no formato correto: <a href="url">texto</a>
        
        # 5. Detectar URLs soltas e converter (apenas se n√£o est√£o dentro de tags HTML ou j√° processadas)
        if '<a href=' not in result:
            loose_url_pattern = r'(https?://[^\s<>()]+)'
            def replace_loose_url(match):
                url = match.group(1)
                logger.info(f"üìù DEBUG: URL solta encontrada: {url}")
                return f'<a href="{url}">{url}</a>'
            result = re.sub(loose_url_pattern, replace_loose_url, result)
        
        logger.info(f"‚úÖ DEBUG: Resultado final da convers√£o de URLs: {result[:200]}...")
        return result 