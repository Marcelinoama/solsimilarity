import re
import requests
import logging
from typing import Dict, List, Optional
from config import Config
import asyncio
import aiohttp
from urllib.parse import urlparse

logger = logging.getLogger(__name__)

class AILinkAnalyzer:
    """Classe para an√°lise de links usando IA (OpenAI)"""
    
    def __init__(self):
        self.openai_api_key = Config.OPENAI_API_KEY
        self.enabled = bool(self.openai_api_key)
        
        if not self.enabled:
            logger.warning("‚ö†Ô∏è OpenAI API key n√£o configurada - an√°lise de links desabilitada")
            logger.info("üí° Adicione OPENAI_API_KEY=sua_chave_aqui no arquivo .env para habilitar")
    
    def extract_social_links(self, social_links_text: str) -> List[Dict[str, str]]:
        """Extrai todos os links da se√ß√£o Social Links"""
        links = []
        
        # Padr√£o para encontrar links HTML: <a href="url">texto</a>
        html_links = re.findall(r'<a href="([^"]+)">[^<]*</a>', social_links_text)
        
        # Padr√£o para encontrar URLs em par√™nteses: (url)
        parentheses_links = re.findall(r'\((https?://[^)]+)\)', social_links_text)
        
        # Padr√£o para encontrar URLs soltas
        loose_links = re.findall(r'(https?://[^\s<>()]+)', social_links_text)
        
        # Combina todos os links √∫nicos
        all_links = list(set(html_links + parentheses_links + loose_links))
        
        for url in all_links:
            # Identifica o tipo de link baseado na URL
            link_type = self._identify_link_type(url)
            links.append({
                'url': url,
                'type': link_type,
                'description': ''
            })
        
        return links
    
    def _identify_link_type(self, url: str) -> str:
        """Identifica o tipo de link baseado na URL"""
        url_lower = url.lower()
        domain = urlparse(url).netloc.lower()
        
        if 'twitter.com' in domain or 'x.com' in domain:
            if '/communities/' in url_lower:
                return 'Twitter Community'
            elif '/status/' in url_lower:
                return 'Twitter Post'
            else:
                return 'Twitter Profile'
        elif 't.me' in domain:
            return 'Telegram'
        elif 't.co' in domain:
            return 'Shortened Link'
        elif 'axiom.trade' in domain:
            return 'Axiom Trading'
        elif any(word in domain for word in ['website', 'site', 'www']):
            return 'Website'
        elif any(ext in domain for ext in ['.com', '.org', '.net', '.io', '.co', '.info', '.news']):
            # Identifica websites comuns por extens√£o de dom√≠nio
            return 'Website'
        else:
            return 'Link'
    
    async def analyze_links_with_ai(self, links: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """Analisa os links usando OpenAI e retorna descri√ß√µes, excluindo links do Axiom"""
        if not self.enabled:
            logger.info("ü§ñ An√°lise de IA desabilitada - retornando tipos b√°sicos")
            return links
        
        try:
            analyzed_links = []
            
            for link_info in links:
                url = link_info['url']
                link_type = link_info['type']
                
                # Verifica se √© link do Axiom - se for, mant√©m formato padr√£o
                if 'axiom.trade' in url.lower() or link_type == 'Axiom Trading':
                    logger.info(f"üö´ Link do Axiom exclu√≠do da an√°lise de IA: {url}")
                    analyzed_links.append({
                        'url': url,
                        'type': link_type,
                        'description': f"Link do tipo {link_type}"  # Formato padr√£o
                    })
                    continue
                
                try:
                    # Faz an√°lise com OpenAI apenas para links n√£o-Axiom
                    description = await self._analyze_single_link(url, link_type)
                    
                    analyzed_links.append({
                        'url': url,
                        'type': link_type,
                        'description': description
                    })
                    
                    # Pequena pausa para evitar rate limiting
                    await asyncio.sleep(0.5)
                    
                except Exception as e:
                    logger.error(f"‚ùå Erro analisando link {url}: {e}")
                    # Fallback para tipo b√°sico
                    analyzed_links.append({
                        'url': url,
                        'type': link_type,
                        'description': f"Link do tipo {link_type}"
                    })
            
            return analyzed_links
            
        except ImportError:
            logger.error("‚ùå Biblioteca openai n√£o instalada. Execute: pip install openai")
            return links
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise de IA: {e}")
            return links
    
    async def _analyze_single_link(self, url: str, link_type: str) -> str:
        """Analisa um √∫nico link usando OpenAI"""
        try:
            from openai import AsyncOpenAI
            
            client = AsyncOpenAI(api_key=self.openai_api_key)
            
            # Prompt otimizado para an√°lise de links de tokens/cripto
            prompt = f"""
Analise este link relacionado a um token de criptomoeda e forne√ßa uma descri√ß√£o concisa em portugu√™s:

URL: {url}
Tipo identificado: {link_type}

Instru√ß√µes:
- Responda em portugu√™s brasileiro
- M√°ximo 50 palavras
- Foque no prop√≥sito/conte√∫do do link
- Se for rede social, mencione o tipo de conte√∫do
- Se for ferramenta/plataforma, explique sua fun√ß√£o
- Use linguagem simples e direta

Descri√ß√£o:"""

            response = await client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em an√°lise de links de projetos de criptomoedas. Forne√ßa descri√ß√µes concisas e √∫teis."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=100,
                temperature=0.3
            )
            
            content = response.choices[0].message.content
            description = content.strip() if content else f"Link do tipo {link_type}"
            return description
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise OpenAI para {url}: {e}")
            return f"Link do tipo {link_type}"
    
    def _sanitize_html_content(self, text: str) -> str:
        """Sanitiza texto para uso seguro em HTML"""
        if not text:
            return ""
        
        # Remove caracteres problem√°ticos e limpa o texto
        text = text.strip()
        # Escapa caracteres HTML b√°sicos mas preserva funcionalidade
        text = text.replace('&', '&amp;')
        text = text.replace('<', '&lt;')
        text = text.replace('>', '&gt;')
        text = text.replace('"', '&quot;')
        text = text.replace("'", '&#x27;')
        
        return text
    
    def _validate_url(self, url: str) -> str:
        """Valida e limpa URL para uso em href"""
        if not url:
            return "#"
        
        url = url.strip()
        
        # Garante que URL tem protocolo
        if not url.startswith(('http://', 'https://', 'ftp://')):
            if 't.me' in url or 'telegram' in url.lower():
                url = f"https://{url}"
            elif url.startswith('www.'):
                url = f"https://{url}"
            elif '.' in url:
                url = f"https://{url}"
        
        # Remove caracteres problem√°ticos
        url = url.replace('"', '%22')
        url = url.replace("'", '%27')
        url = url.replace(' ', '%20')
        
        return url
    
    def format_analyzed_links(self, links: List[Dict[str, str]]) -> str:
        """Formata os links analisados para exibi√ß√£o com sanitiza√ß√£o HTML"""
        if not links:
            return ""
        
        # Verifica se h√° links analisados pela IA (n√£o-Axiom)
        has_ai_analyzed = any(
            link_info.get('description', '') != f"Link do tipo {link_info.get('type', '')}" and 
            'axiom.trade' not in link_info.get('url', '').lower() and
            link_info.get('type', '') != 'Axiom Trading'
            for link_info in links
        )
        
        # Define o cabe√ßalho baseado se tem an√°lise de IA ou n√£o
        if has_ai_analyzed:
            formatted_lines = ["üåê Social Links (An√°lise IA):"]
        else:
            formatted_lines = ["üåê Social Links:"]
        
        for i, link_info in enumerate(links):
            url = self._validate_url(link_info.get('url', ''))
            link_type = self._sanitize_html_content(link_info.get('type', 'Link'))
            description = self._sanitize_html_content(link_info.get('description', ''))
            
            # Caractere de √°rvore
            tree_char = "‚îî" if i == len(links) - 1 else "‚îú"
            
            # Valida se temos dados v√°lidos
            if not url or url == "#" or not link_type:
                continue
                
            # Formata a linha com link clic√°vel e descri√ß√£o
            # Usa URL direta que o Telegram detecta automaticamente como link
            line = f"{tree_char} {link_type} ({url})"
            
            # Adiciona descri√ß√£o apenas se for an√°lise de IA (n√£o para Axiom)
            is_axiom_link = 'axiom.trade' in url.lower() or link_type == 'Axiom Trading'
            has_real_description = description and description != f"Link do tipo {link_type}" and len(description) > 3
            
            if has_real_description and not is_axiom_link:
                line += f" - {description}"
            
            formatted_lines.append(line)
        
        return "\n".join(formatted_lines)
    
    async def analyze_social_links_section(self, social_links_text: str) -> str:
        """M√©todo principal para analisar uma se√ß√£o completa de Social Links"""
        if not social_links_text:
            return ""
        
        try:
            # 1. Extrai os links da se√ß√£o
            links = self.extract_social_links(social_links_text)
            
            if not links:
                logger.info("üìã Nenhum link encontrado na se√ß√£o Social Links")
                return social_links_text
            
            logger.info(f"üîç Encontrados {len(links)} links para an√°lise")
            
            # 2. Analisa com IA (se habilitado)
            analyzed_links = await self.analyze_links_with_ai(links)
            
            # 3. Formata para exibi√ß√£o
            formatted_result = self.format_analyzed_links(analyzed_links)
            
            return formatted_result
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise completa de Social Links: {e}")
            return social_links_text  # Retorna texto original em caso de erro 